{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook ingests the various data files produced by our feature engineering and data collection and aggregates them into a single feature set.  These feature files are saved off as csv files in the associated processed_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,1,2,4,5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Import basic game stats for each NFL game from 2013-2017 seasons\n",
    "cols = ['Key','Pts','FD','Fum','FumL','PY','PA','PI','PS', \n",
    "        'PSY', 'RA', 'RY', 'LWHG', 'DaysSLG',\n",
    "       'qb_relinquished','rb_relinquished','wrte_relinquished',\n",
    "        'qb_val_lost','rb_val_lost','wrte_val_lost','non_key_relinquished']\n",
    "\n",
    "injuries = pd.read_csv(\"n_missed_games_by_annoucement_date.csv\", index_col = 0)\n",
    "injuries['Date'] = pd.to_datetime(injuries['datestring'], format = '%Y%m%d')\n",
    "priors = pd.read_csv(\"starters.csv\", index_col = 0)\n",
    "\n",
    "for y in range(2013,2018):\n",
    "    #Imports and creates initial season game files\n",
    "    game_temp = pd.read_csv(\"base_data/nflstats\" + str(y) + \".csv\")\n",
    "    game_temp.rename(index = str, columns = {'HPS': 'APS', 'HPSY': 'APSY', 'HPS.1':'HPS', 'HPSY.1':'HPSY'}, inplace = True)\n",
    "    game_temp['Datetime'] = pd.to_datetime(game_temp['Start'])\n",
    "    game_temp['Date'] = game_temp['Datetime'].map(lambda x: x.date())\n",
    "    game_temp['Key'] = game_temp['Datetime'].dt.strftime('%Y%m%d') + game_temp['Home']\n",
    "    game_temp['Spread'] = game_temp['HPts'] - game_temp['APts']\n",
    "    \n",
    "    #Filter injury data to the year\n",
    "    start_date = datetime.datetime(year = y, month = 8, day = 15)\n",
    "    end_date = datetime.datetime(year = y + 1, month = 2, day  = 15)\n",
    "    year_mask = injuries['Date'].between(start_date,end_date)\n",
    "    year_injuries = injuries[year_mask]\n",
    "    year_priors = priors.loc[priors['Season'] == y]\n",
    "\n",
    "    #New base dataframe to join everything onto\n",
    "    game_final = game_temp[['Key','Datetime','Home','Away','Spread']]\n",
    "    first_team = True\n",
    "\n",
    "    #Calculate all the cumulative stats\n",
    "    teams = game_temp['Home'].unique()\n",
    "    for t in teams:\n",
    "        \n",
    "        if t == 'STL':\n",
    "            team_injuries = year_injuries.loc[year_injuries['abbr'] == 'LAR']\n",
    "            team_prior = year_priors.loc[year_priors['Team_ID'] == 'LAR']\n",
    "        elif t == 'SDG':\n",
    "            team_injuries = year_injuries.loc[year_injuries['abbr'] == 'LAC']\n",
    "            team_prior = year_priors.loc[year_priors['Team_ID'] == 'LAC']\n",
    "        else:\n",
    "            team_injuries = year_injuries.loc[year_injuries['abbr'] == t]\n",
    "            team_prior = year_priors.loc[year_priors['Team_ID'] == t]\n",
    "        \n",
    "        team_stats = weekly_team_stats(game_temp, team_injuries, team_prior, t, cols, y)\n",
    "        \n",
    "        #Home merge\n",
    "        right = team_stats.add_prefix('H')\n",
    "        right.rename(index = str, columns = {'HKey': 'Key'}, inplace = True)\n",
    "        right['Home'] = t\n",
    "        game_final = game_final.merge(right, how = 'left', on = ['Key', 'Home'])\n",
    "        \n",
    "        #Away merge\n",
    "        right = team_stats.add_prefix('A')\n",
    "        right.rename(index = str, columns = {'AKey': 'Key'}, inplace = True)\n",
    "        right['Away'] = t\n",
    "        game_final = game_final.merge(right, how = 'left', on = ['Key', 'Away'])\n",
    "        \n",
    "        #Take care of dup columns\n",
    "        if first_team:\n",
    "            first_team = False\n",
    "        else:\n",
    "            for col in cols:\n",
    "                if col == 'Key':\n",
    "                    next\n",
    "                else:\n",
    "                    game_final['A'+col] = game_final[['A'+col+'_x', 'A'+col+'_y']].sum(axis = 1)\n",
    "                    game_final['H'+col] = game_final[['H'+col+'_x', 'H'+col+'_y']].sum(axis = 1)\n",
    "                    game_final.drop(['A'+col+'_x', 'A'+col + '_y', 'H'+col+'_x', 'H'+col + '_y'], axis = 1, inplace = True)\n",
    "    \n",
    "        \n",
    "    #Timezone Features\n",
    "    timezones = pd.read_csv(\"timezone_data/timezones\" + str(y) + \".csv\")\n",
    "    \n",
    "    Away_timezones = timezones[['Team_Code','Team_Zone','Zone_Value']]\n",
    "    Away_timezones = Away_timezones.rename(index=str, columns = {\"Team_Code\":\"Away\",\"Team_Zone\":\"AZone\",\"Zone_Value\":\"AZoneVal\"})\n",
    "    game_final = game_final.join(Away_timezones.set_index('Away'), on='Away',how = 'left')\n",
    "\n",
    "    Home_timezones = timezones[['Team_Code','Team_Zone','Zone_Value']]\n",
    "    Home_timezones = Home_timezones.rename(index=str, columns = {\"Team_Code\":\"Home\",\"Team_Zone\":\"HZone\",\"Zone_Value\":\"HZoneVal\"})\n",
    "    game_final = game_final.join(Home_timezones.set_index('Home'), on='Home',how = 'left')\n",
    "    \n",
    "    #Time zone and last week home diffs\n",
    "    game_final = game_final.assign(AZDiff = lambda x: game_final.HZoneVal - game_final.AZoneVal)\n",
    "    game_final = game_final.assign(H_LWGAdv = lambda x: game_final.HLWHG - game_final.ALWHG)\n",
    "    game_final.drop(['HLWHG', 'ALWHG', 'HZone', 'HZoneVal', 'AZone', 'AZoneVal'], axis = 1, inplace = True)\n",
    "\n",
    "    #Stadium Features (only join on Home)\n",
    "    stadiums = pd.read_csv(\"stadiums_data/stadiums\" + str(y) + \".csv\")\n",
    "    stadiums = stadiums[['Team_Code','Turf','Grass','Hybrid','Roof_Open','Roof_Fixed','Roof_Retract']]\n",
    "    stadiums.rename(index = str, columns={'Team_Code':'Home'}, inplace = True)\n",
    "    game_final = game_final.join(stadiums.set_index('Home'), on = 'Home', how = 'left')\n",
    "    \n",
    "    game_final.to_csv('processed_data/'+str(y)+\"processed_extra2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes game stats for each week and breaks them into dataframes of cumulative prior week averages for each team\n",
    "#This is the data we want to use for prediction\n",
    "def weekly_team_stats(stats, injuries, prior, team, cols, year):\n",
    "    t_stats = stats.query('Home == @team | Away == @team')\n",
    "    weekly_stats = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    #Get our \"prior\" for the season\n",
    "    avg_stats = team_stat_priors(team, cols, year, prior)\n",
    "    count = 3\n",
    "    \n",
    "    for index,week in t_stats.iterrows():\n",
    "        week = week.to_dict()\n",
    "        avg_stats['Key'] = week['Key']\n",
    "        last_game_date = avg_stats['DaysSLG']\n",
    "        avg_stats['DaysSLG'] = (week['Date'] - avg_stats['DaysSLG']).days\n",
    "        \n",
    "        #Get Injuries between previous game and current:\n",
    "        injury_mask = (injuries['Date'] < week['Date']) & (injuries['Date'] >= last_game_date)\n",
    "        game_injuries = injuries.loc[injury_mask]\n",
    "        game_injuries.drop(['datestring', 'abbr', 'Date'], axis = 1, inplace = True)\n",
    "        if not game_injuries.empty:\n",
    "            game_injuries = game_injuries.sum()\n",
    "            for key, val in game_injuries.items():\n",
    "                avg_stats[key] = val\n",
    "        \n",
    "        #Add avg stats so far as entry for current week\n",
    "        weekly_stats = weekly_stats.append(avg_stats, ignore_index = True)\n",
    "        \n",
    "        #Get stats for this week\n",
    "        if team == week['Home']:\n",
    "            prefix = 'H'\n",
    "            week.pop('Home')\n",
    "        else:\n",
    "            prefix = 'A'\n",
    "            week.pop('Away')\n",
    "        w_stats = {k[1:]: v for k, v in week.items() if k[0] == prefix}\n",
    "        \n",
    "        #Compute cumulative avgs including this week\n",
    "        count += 1\n",
    "        weight = 1/count\n",
    "        for key,val in avg_stats.items(): \n",
    "            if key == 'Key':\n",
    "                avg_stats[key] = \"Bad Key\"\n",
    "            elif key == 'LWHG':\n",
    "                avg_stats['LWHG'] = int(prefix == 'H')\n",
    "            elif key == 'DaysSLG':\n",
    "                avg_stats['DaysSLG'] = week['Date']\n",
    "            elif '_' in key:\n",
    "                avg_stats[key] = 0\n",
    "            else:\n",
    "                avg_stats[key] = val*(1-weight) + w_stats[key]*weight\n",
    "                \n",
    "    return weekly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates 3 weeks of a \"prior\" data to use in the cumulative stat averaging\n",
    "#This prior is based on avg data in the training set and the distribution of\n",
    "#Player scores at each position for each team\n",
    "#Helps to make predicitons early in the season, diminishes in contribution\n",
    "#To the average as season progresses\n",
    "def team_stat_priors(team, cols, year, prior):\n",
    "    rush_talent = prior['rush_talent'].values[0]\n",
    "    pass_talent = prior['pass_talent'].values[0]\n",
    "    temp = {k:0 for k in cols}\n",
    "    temp['DaysSLG'] = datetime.date(year = year, month = 8, day = 15)\n",
    "    temp['RY'] = 115 #+ #rush_talent * 26\n",
    "    temp['RA'] = 29 #+ #4* rush_talent\n",
    "    temp['PY'] = 235 #+ #(pass_talent - 2.25) * 18\n",
    "    temp['PA'] = 35 #+ #3 * (pass_talent - 2.25)\n",
    "    temp['PI'] = 0.5 #* 1/np.abs(pass_talent + 1)\n",
    "    temp['Pts'] = 23 #+ 5*(rush_talent + pass_talent - 2)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APts</th>\n",
       "      <th>HPts</th>\n",
       "      <th>AFD</th>\n",
       "      <th>AFum</th>\n",
       "      <th>AFumL</th>\n",
       "      <th>APY</th>\n",
       "      <th>APA</th>\n",
       "      <th>API</th>\n",
       "      <th>APS</th>\n",
       "      <th>APSY</th>\n",
       "      <th>...</th>\n",
       "      <th>HFD</th>\n",
       "      <th>HFum</th>\n",
       "      <th>HFumL</th>\n",
       "      <th>HPY</th>\n",
       "      <th>HPA</th>\n",
       "      <th>HPI</th>\n",
       "      <th>HPS</th>\n",
       "      <th>HPSY</th>\n",
       "      <th>HRA</th>\n",
       "      <th>HRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.977528</td>\n",
       "      <td>24.891386</td>\n",
       "      <td>19.337079</td>\n",
       "      <td>1.217228</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>231.696629</td>\n",
       "      <td>35.636704</td>\n",
       "      <td>1.014981</td>\n",
       "      <td>2.636704</td>\n",
       "      <td>17.355805</td>\n",
       "      <td>...</td>\n",
       "      <td>20.595506</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>239.842697</td>\n",
       "      <td>35.011236</td>\n",
       "      <td>0.936330</td>\n",
       "      <td>2.385768</td>\n",
       "      <td>15.602996</td>\n",
       "      <td>28.089888</td>\n",
       "      <td>117.681648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.680199</td>\n",
       "      <td>10.582623</td>\n",
       "      <td>4.944680</td>\n",
       "      <td>1.122900</td>\n",
       "      <td>0.747632</td>\n",
       "      <td>75.744536</td>\n",
       "      <td>8.857638</td>\n",
       "      <td>1.058336</td>\n",
       "      <td>1.725266</td>\n",
       "      <td>12.932619</td>\n",
       "      <td>...</td>\n",
       "      <td>5.124141</td>\n",
       "      <td>1.212921</td>\n",
       "      <td>0.759070</td>\n",
       "      <td>83.419841</td>\n",
       "      <td>8.823875</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.700581</td>\n",
       "      <td>11.973956</td>\n",
       "      <td>7.972189</td>\n",
       "      <td>52.795817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>81.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             APts        HPts         AFD        AFum       AFumL         APY  \\\n",
       "count  267.000000  267.000000  267.000000  267.000000  267.000000  267.000000   \n",
       "mean    21.977528   24.891386   19.337079    1.217228    0.588015  231.696629   \n",
       "std      9.680199   10.582623    4.944680    1.122900    0.747632   75.744536   \n",
       "min      0.000000    0.000000    6.000000    0.000000    0.000000   89.000000   \n",
       "25%     16.000000   19.000000   16.000000    0.000000    0.000000  176.500000   \n",
       "50%     21.000000   24.000000   19.000000    1.000000    0.000000  221.000000   \n",
       "75%     27.000000   31.000000   23.000000    2.000000    1.000000  283.000000   \n",
       "max     56.000000   55.000000   34.000000    7.000000    5.000000  428.000000   \n",
       "\n",
       "              APA         API         APS        APSY     ...             HFD  \\\n",
       "count  267.000000  267.000000  267.000000  267.000000     ...      267.000000   \n",
       "mean    35.636704    1.014981    2.636704   17.355805     ...       20.595506   \n",
       "std      8.857638    1.058336    1.725266   12.932619     ...        5.124141   \n",
       "min     16.000000    0.000000    0.000000    0.000000     ...        9.000000   \n",
       "25%     29.000000    0.000000    1.000000    7.000000     ...       17.500000   \n",
       "50%     35.000000    1.000000    2.000000   16.000000     ...       20.000000   \n",
       "75%     41.000000    2.000000    4.000000   25.500000     ...       24.000000   \n",
       "max     62.000000    5.000000    9.000000   63.000000     ...       40.000000   \n",
       "\n",
       "             HFum       HFumL         HPY         HPA         HPI         HPS  \\\n",
       "count  267.000000  267.000000  267.000000  267.000000  267.000000  267.000000   \n",
       "mean     1.333333    0.614232  239.842697   35.011236    0.936330    2.385768   \n",
       "std      1.212921    0.759070   83.419841    8.823875    0.996078    1.700581   \n",
       "min      0.000000    0.000000   46.000000   15.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000  180.000000   28.000000    0.000000    1.000000   \n",
       "50%      1.000000    0.000000  231.000000   35.000000    1.000000    2.000000   \n",
       "75%      2.000000    1.000000  296.000000   41.000000    1.000000    3.000000   \n",
       "max      6.000000    3.000000  480.000000   59.000000    5.000000    9.000000   \n",
       "\n",
       "             HPSY         HRA         HRY  \n",
       "count  267.000000  267.000000  267.000000  \n",
       "mean    15.602996   28.089888  117.681648  \n",
       "std     11.973956    7.972189   52.795817  \n",
       "min      0.000000    9.000000   18.000000  \n",
       "25%      7.000000   22.000000   81.500000  \n",
       "50%     14.000000   29.000000  111.000000  \n",
       "75%     23.000000   34.000000  149.000000  \n",
       "max     54.000000   55.000000  299.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv(\"base_data/nflstats2013.csv\")\n",
    "temp.rename(index = str, columns = {'HPS': 'APS', 'HPSY': 'APSY', 'HPS.1':'HPS', 'HPSY.1':'HPSY'}, inplace = True)\n",
    "temp.drop(['Season', 'Week', 'OverUnder', 'VegasLine'], axis = 1, inplace = True)\n",
    "temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debugging\n",
    "teams = game_stats['Home'].unique()\n",
    "team_stats = {}\n",
    "for t in teams:\n",
    "    team_stats.update({t:weekly_team_stats(game_stats, t)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Key      Pts       FD      Fum      FumL       PY       PA  \\\n",
      "0             0        0        0        0         0        0        0   \n",
      "1   20140907NYJ       19       20        2         1      190       29   \n",
      "2   20140914GNB     21.5     19.5      1.5       0.5      178     30.5   \n",
      "3   20140922NYJ  20.6667       20  2.66667  0.666667  218.667  34.6667   \n",
      "4   20140928NYJ    19.75    19.25      2.5      0.75      215    34.25   \n",
      "5   20141005SDG     15.8     17.6      2.2       0.8      184     33.6   \n",
      "6   20141012NYJ       16  17.1667  2.16667  0.833333  182.167  35.1667   \n",
      "7   20141016NWE  17.2857  18.7143        2  0.714286  185.429       35   \n",
      "8   20141026NYJ       18   19.125     2.25     0.875  179.375   36.125   \n",
      "9   20141102KAN  17.1111  19.4444  2.11111  0.777778  184.444  36.1111   \n",
      "10  20141109NYJ     17.4       19      1.9       0.7    178.5     34.3   \n",
      "11  20141124BUF  16.0909  18.2727  1.72727  0.636364  173.727       34   \n",
      "12  20141201NYJ  15.8333    18.25  1.66667  0.583333  163.333    32.25   \n",
      "13  20141207MIN  16.4615  18.3077  1.84615  0.615385  169.385       32   \n",
      "14  20141214TEN  16.4286  18.2143  1.71429  0.571429  168.929  31.7143   \n",
      "15  20141221NYJ     16.4  18.0667      1.6  0.533333    170.4     31.4   \n",
      "\n",
      "         PI       PS      PSY       RA       RY  \n",
      "0         0        0        0        0        0  \n",
      "1         1        2       31       34      212  \n",
      "2         1        2     20.5     35.5    179.5  \n",
      "3   1.33333  2.33333       19  32.3333  157.667  \n",
      "4      1.25     2.25     15.5       31   151.25  \n",
      "5       1.2      2.2     15.2       29    139.2  \n",
      "6   1.16667      2.5     15.5  26.6667  121.167  \n",
      "7         1  2.57143  16.2857       29      135  \n",
      "8     1.375     2.75   16.875     29.5      140  \n",
      "9   1.22222  2.77778  16.1111  29.5556  139.889  \n",
      "10      1.1      2.9     15.2     30.2    140.9  \n",
      "11  1.09091  3.27273  17.3636  29.1818  136.455  \n",
      "12  1.08333  3.16667    17.25  30.8333  148.167  \n",
      "13  1.07692  3.15385  16.8462  31.6923  149.692  \n",
      "14        1  3.14286  16.7857     31.5  147.143  \n",
      "15        1  3.06667  16.9333  31.5333  145.067  \n"
     ]
    }
   ],
   "source": [
    "#Debugging\n",
    "print(team_stats['NYJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIN' 'PHI' 'ATL' 'DAL' 'DEN' 'HOU' 'IND' 'JAX' 'LAR' 'MIN' 'NOR' 'NYG'\n",
      " 'SFO' 'TAM' 'GNB' 'SEA' 'ARI' 'BUF' 'LAC' 'NWE' 'OAK' 'PIT' 'TEN' 'CHI'\n",
      " 'NYJ' 'CAR' 'DET' 'WAS' 'MIA' 'BAL' 'KAN' 'CLE']\n"
     ]
    }
   ],
   "source": [
    "injuries = pd.read_csv(\"n_missed_games_by_annoucement_date.csv\")\n",
    "print(injuries['abbr'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
