{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import os \n",
    "import os.path\n",
    "import csv \n",
    "import time \n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"credit: http://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/\"\n",
    "\n",
    "class HTMLTableParser:\n",
    "       \n",
    "    def parse_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        return [(table,self.parse_html_table(table))\\\n",
    "                for table in soup.find_all('table')]  \n",
    "    \n",
    "    def parse_html_table(self, table):\n",
    "        \n",
    "        \n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "    \n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "                \n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "                        \n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('nbsp') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "    \n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            raise Exception(\"Column titles do not match the number of columns\")\n",
    "    \n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = ['Date','Team','Acquired','Relinquished','Notes'],index= range(0,n_rows))\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "                \n",
    "                    \n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        df = df.drop(df.index[0])\n",
    "        \n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtm'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#URL to scrape\n",
    "url = \"https://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&ILChkBx=yes&submit=Search\"\n",
    "\n",
    "#access URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Access the HTML with the text property\n",
    "response.text[:100] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Acquired</th>\n",
       "      <th>Relinquished</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Falcons</td>\n",
       "      <td></td>\n",
       "      <td>• Andy Levitre</td>\n",
       "      <td>placed on IR with triceps injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Panthers</td>\n",
       "      <td></td>\n",
       "      <td>• Chris Manhertz</td>\n",
       "      <td>placed on IR with ankle injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>• Carson Palmer</td>\n",
       "      <td></td>\n",
       "      <td>activated from IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Chiefs</td>\n",
       "      <td></td>\n",
       "      <td>• Phillip Gaines</td>\n",
       "      <td>placed on IR with dislocated elbow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Saints</td>\n",
       "      <td></td>\n",
       "      <td>• Garrett Griffin</td>\n",
       "      <td>placed on IR with foot injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>Vikings</td>\n",
       "      <td></td>\n",
       "      <td>• Dylan Bradley</td>\n",
       "      <td>placed on practice squad IR with undisclosed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Saints</td>\n",
       "      <td></td>\n",
       "      <td>• Andrus Peat</td>\n",
       "      <td>placed on IR with fractured fibula in leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Saints</td>\n",
       "      <td></td>\n",
       "      <td>• Tony McDaniel</td>\n",
       "      <td>placed on IR with leg injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>• Sam Bradford</td>\n",
       "      <td></td>\n",
       "      <td>activated from IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>Patriots</td>\n",
       "      <td></td>\n",
       "      <td>• Jonathan Jones</td>\n",
       "      <td>placed on IR with ankle injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>Colts</td>\n",
       "      <td>• Edwin Jackson</td>\n",
       "      <td></td>\n",
       "      <td>activated from IR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Team          Acquired        Relinquished  \\\n",
       "1   2018-01-02     Falcons                        • Andy Levitre   \n",
       "2   2018-01-02    Panthers                      • Chris Manhertz   \n",
       "3   2018-01-02   Cardinals   • Carson Palmer                       \n",
       "4   2018-01-03      Chiefs                      • Phillip Gaines   \n",
       "5   2018-01-03      Saints                     • Garrett Griffin   \n",
       "6   2018-01-09     Vikings                       • Dylan Bradley   \n",
       "7   2018-01-10      Saints                         • Andrus Peat   \n",
       "8   2018-01-10      Saints                       • Tony McDaniel   \n",
       "9   2018-01-13     Vikings    • Sam Bradford                       \n",
       "10  2018-01-17    Patriots                      • Jonathan Jones   \n",
       "11  2018-02-04       Colts   • Edwin Jackson                       \n",
       "\n",
       "                                                Notes  \n",
       "1                    placed on IR with triceps injury  \n",
       "2                      placed on IR with ankle injury  \n",
       "3                                   activated from IR  \n",
       "4                  placed on IR with dislocated elbow  \n",
       "5                       placed on IR with foot injury  \n",
       "6    placed on practice squad IR with undisclosed ...  \n",
       "7           placed on IR with fractured fibula in leg  \n",
       "8                        placed on IR with leg injury  \n",
       "9                                   activated from IR  \n",
       "10                     placed on IR with ankle injury  \n",
       "11                                  activated from IR  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HTMLTableParser()\n",
    "table = hp.parse_url(url)[0][1] # Grabbing the table from the tuple\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Acquired</th>\n",
       "      <th>Relinquished</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Falcons</td>\n",
       "      <td></td>\n",
       "      <td>Andy Levitre</td>\n",
       "      <td>placed on IR with triceps injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Panthers</td>\n",
       "      <td></td>\n",
       "      <td>Chris Manhertz</td>\n",
       "      <td>placed on IR with ankle injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td></td>\n",
       "      <td>activated from IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Chiefs</td>\n",
       "      <td></td>\n",
       "      <td>Phillip Gaines</td>\n",
       "      <td>placed on IR with dislocated elbow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Saints</td>\n",
       "      <td></td>\n",
       "      <td>Garrett Griffin</td>\n",
       "      <td>placed on IR with foot injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>Vikings</td>\n",
       "      <td></td>\n",
       "      <td>Dylan Bradley</td>\n",
       "      <td>placed on practice squad IR with undisclosed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Saints</td>\n",
       "      <td></td>\n",
       "      <td>Andrus Peat</td>\n",
       "      <td>placed on IR with fractured fibula in leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Saints</td>\n",
       "      <td></td>\n",
       "      <td>Tony McDaniel</td>\n",
       "      <td>placed on IR with leg injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>Sam Bradford</td>\n",
       "      <td></td>\n",
       "      <td>activated from IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>Patriots</td>\n",
       "      <td></td>\n",
       "      <td>Jonathan Jones</td>\n",
       "      <td>placed on IR with ankle injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>Colts</td>\n",
       "      <td>Edwin Jackson</td>\n",
       "      <td></td>\n",
       "      <td>activated from IR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Team         Acquired       Relinquished  \\\n",
       "1   2018-01-02     Falcons                        Andy Levitre   \n",
       "2   2018-01-02    Panthers                      Chris Manhertz   \n",
       "3   2018-01-02   Cardinals    Carson Palmer                      \n",
       "4   2018-01-03      Chiefs                      Phillip Gaines   \n",
       "5   2018-01-03      Saints                     Garrett Griffin   \n",
       "6   2018-01-09     Vikings                       Dylan Bradley   \n",
       "7   2018-01-10      Saints                         Andrus Peat   \n",
       "8   2018-01-10      Saints                       Tony McDaniel   \n",
       "9   2018-01-13     Vikings     Sam Bradford                      \n",
       "10  2018-01-17    Patriots                      Jonathan Jones   \n",
       "11  2018-02-04       Colts    Edwin Jackson                      \n",
       "\n",
       "                                                Notes  \n",
       "1                    placed on IR with triceps injury  \n",
       "2                      placed on IR with ankle injury  \n",
       "3                                   activated from IR  \n",
       "4                  placed on IR with dislocated elbow  \n",
       "5                       placed on IR with foot injury  \n",
       "6    placed on practice squad IR with undisclosed ...  \n",
       "7           placed on IR with fractured fibula in leg  \n",
       "8                        placed on IR with leg injury  \n",
       "9                                   activated from IR  \n",
       "10                     placed on IR with ankle injury  \n",
       "11                                  activated from IR  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.replace('\\•','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write table to csv\n",
    "table.to_csv(\"table\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#INJURIES scaper\n",
    "hp = HTMLTableParser()\n",
    "\n",
    "#base URL to scrape\n",
    "#dates 01/01/2009-02/04/2018 (superbowl)\n",
    "base_url = \"https://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&ILChkBx=yes&submit=Search\"\n",
    "\n",
    "#create CSVs for each search page table -- 388 pages total\n",
    "for i in range(0,389):\n",
    "    if i == 0:\n",
    "        #URL to scrape\n",
    "        url = base_url\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('inj_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "    else:\n",
    "        url = base_url+'&start='+str(25*i)\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('inj_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "\n",
    "#combine CSVs\n",
    "\n",
    "fout=open(\"injuries.csv\",\"a\")\n",
    "# first file:\n",
    "for line in open(\"inj_table_0\"):\n",
    "    fout.write(line)\n",
    "# now the rest:    \n",
    "for num in range(1,389):\n",
    "    f = open(\"inj_table_\"+str(num))\n",
    "    f.__next__() # skip the header\n",
    "    for line in f:\n",
    "        fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Player/Coach/Exec Movements Scraper\n",
    "\n",
    "hp = HTMLTableParser()\n",
    "\n",
    "#base URL to scrape\n",
    "#dates 01/01/2009-02/04/2018 (superbowl)\n",
    "base_url = \"https://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&PlayerMovementChkBx=yes&submit=Search\"\n",
    "\n",
    "#create CSVs for each search page table -- 2639 pages total\n",
    "for i in range(0,2640):\n",
    "    if i == 0:\n",
    "        #URL to scrape\n",
    "        url = base_url\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "    else:\n",
    "        url = base_url+'&start='+str(25*i)\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('table'+'_'+str(i), encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine CSVs - for Player/Coach/Exec Movements\n",
    "\n",
    "fout=open(\"pce_movements.csv\",\"a\")\n",
    "# first file:\n",
    "for line in open(\"table_0\"):\n",
    "    fout.write(line)\n",
    "# now the rest:    \n",
    "for num in range(1,2640):\n",
    "    f = open(\"table_\"+str(num))\n",
    "    f.__next__() # skip the header\n",
    "    for line in f:\n",
    "        fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missed games due to injury\n",
    "\n",
    "hp = HTMLTableParser()\n",
    "\n",
    "#base URL to scrape\n",
    "#dates 01/01/2009-02/04/2018 (superbowl)\n",
    "base_url = \"https://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&InjuriesChkBx=yes&submit=Search\"\n",
    "\n",
    "#create CSVs for each search page table -- 285 pages total\n",
    "for i in range(0,286):\n",
    "    if i == 0:\n",
    "        #URL to scrape\n",
    "        url = base_url\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('mg_i_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "    else:\n",
    "        url = base_url+'&start='+str(25*i)\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('mg_i_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "        \n",
    "\n",
    "#combine CSVs\n",
    "\n",
    "fout=open(\"missed_games_injury.csv\",\"a\")\n",
    "# first file:\n",
    "for line in open(\"mg_i_table_0\"):\n",
    "    fout.write(line)\n",
    "# now the rest:    \n",
    "for num in range(1,286):\n",
    "    f = open(\"mg_i_table_\"+str(num))\n",
    "    f.__next__() # skip the header\n",
    "    for line in f:\n",
    "        fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#missed games due to personal reasons\n",
    "\n",
    "hp = HTMLTableParser()\n",
    "\n",
    "#base URL to scrape\n",
    "#dates 01/01/2009-02/04/2018 (superbowl) \n",
    "base_url = \"http://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&PersonalChkBx=yes&submit=Search\"\n",
    "\n",
    "#URL to scrape - only 1 page\n",
    "url = base_url\n",
    "#create table\n",
    "file = hp.parse_url(url)[0][1]\n",
    "file = file.replace('\\•','',regex=True)\n",
    "#write to CSV\n",
    "file.to_csv('mg_pr_table', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#disciplinary actions(suspensions, fines, etc.)\n",
    "\n",
    "hp = HTMLTableParser()\n",
    "\n",
    "#base URL to scrape\n",
    "#dates 01/01/2009-02/04/2018 (superbowl)\n",
    "base_url = \"http://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&DisciplinaryChkBx=yes&submit=Search\"\n",
    "\n",
    "\n",
    "#create CSVs for each search page table -- 58 pages\n",
    "for i in range(0,59):\n",
    "    if i == 0:\n",
    "        #URL to scrape\n",
    "        url = base_url\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('dis_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "    else:\n",
    "        url = base_url+'&start='+str(25*i)\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('dis_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "        \n",
    "#combine CSVs\n",
    "\n",
    "fout=open(\"disciplinary.csv\",\"a\")\n",
    "# first file:\n",
    "for line in open(\"dis_table_0\"):\n",
    "    fout.write(line)\n",
    "# now the rest:    \n",
    "for num in range(1,58):\n",
    "    f = open(\"dis_table_\"+str(num))\n",
    "    f.__next__() # skip the header\n",
    "    for line in f:\n",
    "        fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#legal/criminal incidents\n",
    "\n",
    "hp = HTMLTableParser()\n",
    "\n",
    "#base URL to scrape\n",
    "#dates 01/01/2009-02/04/2018 (superbowl)\n",
    "base_url = \"http://www.prosportstransactions.com/football/Search/SearchResults.php?Player=&Team=&BeginDate=2009-01-01&EndDate=2018-02-04&LegalChkBx=yes&submit=Search\"\n",
    "\n",
    "\n",
    "#create CSVs for each search page table -- 9 pages\n",
    "for i in range(0,10):\n",
    "    if i == 0:\n",
    "        #URL to scrape\n",
    "        url = base_url\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('leg_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "    else:\n",
    "        url = base_url+'&start='+str(25*i)\n",
    "        #create table\n",
    "        file = hp.parse_url(url)[0][1]\n",
    "        file = file.replace('\\•','',regex=True)\n",
    "        #write to CSV\n",
    "        file.to_csv('leg_table'+'_'+str(i), encoding='utf-8', index=False)\n",
    "        \n",
    "#combine CSVs\n",
    "\n",
    "fout=open(\"legal.csv\",\"a\")\n",
    "# first file:\n",
    "for line in open(\"leg_table_0\"):\n",
    "    fout.write(line)\n",
    "# now the rest:    \n",
    "for num in range(1,9):\n",
    "    f = open(\"leg_table_\"+str(num))\n",
    "    f.__next__() # skip the header\n",
    "    for line in f:\n",
    "        fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
